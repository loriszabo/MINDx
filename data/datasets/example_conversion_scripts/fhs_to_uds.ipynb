{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process of converting FHS dataset to UDS format\n",
    "\n",
    "Note: Please Download FHS datasets from (<a href=\"https://www.framinghamheartstudy.org/fhs-for-researchers/data-available-overview/\">www.framinghamheartstudy.org/fhs-for-researchers/data-available-overview/</a>) prior to running this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cu0 = pd.read_csv('Generation-1/curated_bap_0_0919_nolabel.csv')\n",
    "cu0 = cu0[~cu0['demrv046'].isna()].dropna(subset=['normal_date', 'impairment_date', 'mild_date', 'moderate_date', 'severe_date'], how='all')\n",
    "cu0.columns = cu0.columns.str.lower()\n",
    "\n",
    "cu17 = pd.read_csv('Generation-2/curated_bap_17_0712_nolabel.csv')\n",
    "cu17 = cu17[~cu17['demrv046'].isna()].dropna(subset=['normal_date', 'impairment_date', 'mild_date', 'moderate_date', 'severe_date'], how='all')\n",
    "cu17.columns = cu17.columns.str.lower()\n",
    "\n",
    "mri = pd.read_csv('FHS_MRI_All.csv')\n",
    "mri.columns = mri.columns.str.lower()\n",
    "\n",
    "# Maximum difference between different test visits\n",
    "diff_months = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dates to pandas datetime object\n",
    "for col in cu0.columns:\n",
    "    try:\n",
    "        # Try converting each column to datetime\n",
    "        cu0[col] = pd.to_datetime(cu0[col], format='%m/%d/%Y', errors='raise')\n",
    "    except ValueError:\n",
    "        # If conversion fails, move to the next column\n",
    "        continue\n",
    "    \n",
    "    \n",
    "for col in cu17.columns:\n",
    "    try:\n",
    "        # Try converting each column to datetime\n",
    "        cu17[col] = pd.to_datetime(cu17[col], format='%m/%d/%Y', errors='raise')\n",
    "    except ValueError:\n",
    "        # If conversion fails, move to the next column\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot on mri dates and mri locations\n",
    "def convert_date(date_int):\n",
    "    date_str = str(date_int)\n",
    "    if len(date_str) != 8:\n",
    "        raise ValueError(\"Date must be in yyyymmdd format\")\n",
    "    year = date_str[0:4]\n",
    "    month = date_str[4:6]\n",
    "    day = date_str[6:8]\n",
    "    return f\"{month}/{day}/{year}\"\n",
    "\n",
    "mri['date'] = mri['date'].apply(convert_date)\n",
    "\n",
    "mri['date_rank'] = mri.groupby('id').cumcount() + 1\n",
    "\n",
    "# Pivot the DataFrame for 'date'\n",
    "mri_pivot_date = mri.pivot_table(index=['id', 'idtype'], columns='date_rank', values='date', aggfunc='first').reset_index()\n",
    "mri_pivot_date.columns = ['id', 'idtype'] + [f'mri_date{i}' for i in range(1, len(mri_pivot_date.columns) - 1)]\n",
    "\n",
    "# Pivot the DataFrame for 'dst'\n",
    "mri_pivot_dst = mri.pivot_table(index=['id', 'idtype'], columns='date_rank', values='dst', aggfunc='first').reset_index()\n",
    "mri_pivot_dst.columns = ['id', 'idtype'] + [f'mri_dst{i}' for i in range(1, len(mri_pivot_dst.columns) - 1)]\n",
    "\n",
    "# Pivot the DataFrame for 'id_date'\n",
    "mri_pivot_id_date = mri.pivot_table(index=['id', 'idtype'], columns='date_rank', values='id_date', aggfunc='first').reset_index()\n",
    "mri_pivot_id_date.columns = ['id', 'idtype'] + [f'mri_id_date{i}' for i in range(1, len(mri_pivot_id_date.columns) - 1)]\n",
    "\n",
    "# Merge the two pivoted DataFrames\n",
    "mri_combined = pd.merge(mri_pivot_date, mri_pivot_dst, on=['id', 'idtype'])\n",
    "\n",
    "mri_combined = pd.merge(mri_combined, mri_pivot_id_date, on=['id', 'idtype'])\n",
    "\n",
    "for col in mri_combined.columns:\n",
    "    try:\n",
    "        # Try converting each column to datetime\n",
    "        mri_combined[col] = pd.to_datetime(mri_combined[col], format='%m/%d/%Y', errors='raise')\n",
    "    except ValueError:\n",
    "        # If conversion fails, move to the next column\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge mris with data\n",
    "cu0_merged = pd.merge(cu0, mri_combined, on=['idtype', 'id'], how='left')\n",
    "cu17_merged = pd.merge(cu17, mri_combined, on=['idtype', 'id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get date of diagnosis\n",
    "def get_diagnosis_date(row):\n",
    "    # print(row['mild_date'])\n",
    "    if isinstance(row['mild_date'], pd.Timestamp):\n",
    "        row['diag_date'] = row['mild_date']\n",
    "    elif isinstance(row['moderate_date'], pd.Timestamp):\n",
    "        row['diag_date'] = row['moderate_date']\n",
    "    elif isinstance(row['severe_date'], pd.Timestamp):\n",
    "        row['diag_date'] = row['severe_date']\n",
    "    elif isinstance(row['impairment_date'], pd.Timestamp):\n",
    "        row['diag_date'] = row['impairment_date']\n",
    "    elif isinstance(row['normal_date'], pd.Timestamp):\n",
    "        row['diag_date'] = row['normal_date']\n",
    "    return row\n",
    "\n",
    "cu0_merged = cu0_merged.apply(get_diagnosis_date, axis=1)\n",
    "cu17_merged = cu17_merged.apply(get_diagnosis_date, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the closest visit information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the visit numbers for different exams (date_core, np, mri) within 6 months of diagnosis date\n",
    "\n",
    "import re\n",
    "def extract_number(col_name):\n",
    "    \"\"\"Extract the trailing number from the column name.\"\"\"\n",
    "    match = re.search(r'(\\d+)$', col_name)\n",
    "    return int(match.group()) if match else 0\n",
    "\n",
    "def select_tests(row):\n",
    "    cols = row.index\n",
    "    date_core = sorted([col for col in cols if 'date_core' in col], key=extract_number, reverse=True)\n",
    "    examdate_np = sorted([col for col in cols if 'examdate_np' in col], key=extract_number, reverse=True)\n",
    "    mri_date = sorted([col for col in cols if 'mri_date' in col], key=extract_number, reverse=True)\n",
    "    \n",
    "    diff = pd.DateOffset(months=diff_months)\n",
    "    # print((row['diag_date'] - diff))\n",
    "    \n",
    "    for col in date_core:\n",
    "        if (not isinstance(row[col], float)) and (not isinstance(row[col], str)) and (not pd.isna(row[col])) and (row[col] >= (row['diag_date'] - diff) and row[col] <= (row['diag_date'] + diff)):\n",
    "            # row['_'.join(col.split('_')[:-1]) + '_core'] = row[col]\n",
    "            row['_'.join(col.split('_')[:-1]) + '_core_no'] = int(re.search(r'(\\d+)$', col).group())\n",
    "            break\n",
    "        # row['_'.join(col.split('_')[:-1]) + '_core'] = pd.to_datetime(np.NaN)\n",
    "        row['_'.join(col.split('_')[:-1]) + '_core_no'] = np.NaN\n",
    "        \n",
    "    for col in examdate_np:\n",
    "        if (not isinstance(row[col], float)) and (not isinstance(row[col], str)) and (not pd.isna(row[col]))  and (row[col] >= (row['diag_date'] - diff) and row[col] <= (row['diag_date'] + diff)):\n",
    "            # row['_'.join(col.split('_')[:-1]) + '_np'] = row[col]\n",
    "            row['_'.join(col.split('_')[:-1]) + '_np_no'] = int(re.search(r'(\\d+)$', col).group())\n",
    "            break\n",
    "        # row['_'.join(col.split('_')[:-1]) + '_np'] = pd.to_datetime(np.NaN)\n",
    "        row['_'.join(col.split('_')[:-1]) + '_np_no'] = np.NaN\n",
    "    \n",
    "    for col in mri_date:\n",
    "        if (not isinstance(row[col], float)) and (not isinstance(row[col], str)) and (not pd.isna(row[col]))  and (row[col] >= (row['diag_date'] - diff) and row[col] <= (row['diag_date'] + diff)):\n",
    "            # row['_'.join(col.split('_')[:-1]) + '_date'] = row[col]\n",
    "            row['_'.join(col.split('_')[:-1]) + '_date_no'] = int(re.search(r'(\\d+)$', col).group())\n",
    "            break\n",
    "        # row['_'.join(col.split('_')[:-1]) + '_date'] = pd.to_datetime(np.NaN)\n",
    "        row['_'.join(col.split('_')[:-1]) + '_date_no'] = np.NaN\n",
    "        \n",
    "    return row\n",
    "    \n",
    "cu0_merged_ = cu0_merged.apply(select_tests, axis=1)\n",
    "cu17_merged_ = cu17_merged.apply(select_tests, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all test values for the selected visit numbers\n",
    "def get_correct_columns(row):\n",
    "    cols = row.index\n",
    "    # core_values = set(['_'.join(col.split('_')[:-1]) + '_core' for col in cols if '_core' in col.lower() and 'date_col' not in col])\n",
    "    core_values = set()\n",
    "    for col in cols:\n",
    "        if 'date_core' in col:\n",
    "            continue\n",
    "        if '_core' in col.lower():\n",
    "            tmp = col.split('_')\n",
    "            for i, wrd in enumerate(tmp):\n",
    "                if 'core' in wrd.lower():\n",
    "                    tmp[i] = 'core'\n",
    "                    break\n",
    "            core_values.add('_'.join(tmp))\n",
    "        \n",
    "    np_values = set(['_'.join(col.split('_')[:-1]) + '_np' for col in cols if '_np' in col.lower() and 'examdate_np' not in col])\n",
    "    # print(core_values)\n",
    "    # print(type(row['date_core_no']), row['date_core_no'])\n",
    "    if 'date_core_no' in row and not pd.isna(row['date_core_no']):\n",
    "        date_core_no = int(row['date_core_no'])\n",
    "        row['date_core'] = row[f'date_core{date_core_no}']\n",
    "        for col in core_values:\n",
    "            # print(f'{core_col}{exam_cycle}', index)\n",
    "            tmp = col.split('_')\n",
    "            for i, wrd in enumerate(tmp):\n",
    "                if 'core' in wrd:\n",
    "                    tmp[i] = f'core{date_core_no}'\n",
    "            tmp = '_'.join(tmp)\n",
    "            if tmp in row:\n",
    "                if col != '_'.join(col.split('_')[:-1]) + '_core':\n",
    "                    print(col, '_'.join(col.split('_')[:-1]) + '_core')\n",
    "                row[col] = row[tmp]\n",
    "            else:\n",
    "                row[col] = np.NaN\n",
    "    else:\n",
    "        if 'date_core' not in row.index:\n",
    "            row['date_core'] = pd.to_datetime(np.NaN)\n",
    "        for col in core_values:\n",
    "            if col not in row.index:\n",
    "                row[col] = np.NaN\n",
    "    \n",
    "    \n",
    "    if 'examdate_np_no' in row and not pd.isna(row['examdate_np_no']):    \n",
    "        examdate_np_no = int(row['examdate_np_no'])\n",
    "        row['examdate_np'] = row[f'examdate_np{examdate_np_no}']\n",
    "                \n",
    "        for col in np_values:\n",
    "            # print(f'{core_col}{exam_cycle}', index)\n",
    "            if col != '_'.join(col.split('_')[:-1]) + '_np':\n",
    "                print(col, '_'.join(col.split('_')[:-1]) + '_np')\n",
    "            if f'{col}{examdate_np_no}' in row:\n",
    "                row[col] = row[f'{col}{examdate_np_no}']\n",
    "            else:\n",
    "                row[col] = np.NaN\n",
    "    else:\n",
    "        if 'examdate_np' not in row.index:\n",
    "            row['examdate_np'] = pd.to_datetime(np.NaN)\n",
    "        for col in np_values:\n",
    "            if col not in row.index:\n",
    "                row[col] = np.NaN\n",
    "            \n",
    "    if 'mri_date_no' in row and not pd.isna(row['mri_date_no']):\n",
    "        mri_date_no = int(row['mri_date_no'])\n",
    "        row['mri_date'] = row[f'mri_date{mri_date_no}']\n",
    "        row['mri_dst'] = row[f'mri_dst{mri_date_no}']\n",
    "        row['mri_id_date'] = row[f'mri_id_date{mri_date_no}']\n",
    "    else:\n",
    "        if 'mri_date' not in row.index:\n",
    "            row['mri_date'] = pd.to_datetime(np.NaN)\n",
    "        \n",
    "        if 'mri_dst' not in row.index:\n",
    "            row['mri_dst'] = np.NaN\n",
    "            \n",
    "        if 'mri_id_date' not in row.index:\n",
    "            row['mri_id_date'] = np.NaN\n",
    "            \n",
    "    return row\n",
    "\n",
    "# cu0_merged_[:100].apply(get_correct_columns, axis=1)\n",
    "\n",
    "cu0_merged_conv = cu0_merged_.apply(get_correct_columns, axis=1)\n",
    "cu17_merged_conv = cu17_merged_.apply(get_correct_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cu0_merged_conv.to_csv(f'fhs_cu0_merged_conv_{diff_months}months.csv', index=False)\n",
    "cu17_merged_conv.to_csv(f'fhs_cu17_merged_conv_{diff_months}months.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdr_val(row):\n",
    "    if isinstance(row['severe_date'], pd.Timestamp):\n",
    "        return 3.0\n",
    "    elif isinstance(row['moderate_date'], pd.Timestamp):\n",
    "        return 2.0\n",
    "    elif isinstance(row['mild_date'], pd.Timestamp):\n",
    "        return 1.0\n",
    "    elif isinstance(row['impairment_date'], pd.Timestamp):\n",
    "        return 0.5\n",
    "    elif isinstance(row['normal_date'], pd.Timestamp):\n",
    "        return 0.0\n",
    "    return np.NaN\n",
    "\n",
    "# get final columns and merge the two datasets\n",
    "intersect = list(set(list(cu0_merged_conv.columns)).intersection(set(list(cu17_merged_conv.columns))))\n",
    "intersect = [col for col in intersect if 'mri_date' not in col and 'mri_dst' not in col and 'mri_id_date' not in col and '_np' not in col and '_core' not in col]\n",
    "columns = sorted(intersect) + ['date_core', 'examdate_np', 'mri_date', 'mri_dst', 'mri_id_date', 'date_core_no', 'examdate_np_no', 'mri_date_no'] + list(set(['_'.join(col.split('_')[:-1]) + '_core' for col in cu0_merged_.columns.to_list() if '_core' in col.lower() and 'date_core' not in col])) + list(set(['_'.join(col.split('_')[:-1]) + '_np' for col in cu0_merged_.columns.to_list() if '_np' in col.lower() and 'examdate_np' not in col]))\n",
    "\n",
    "cu0_final = cu0_merged_conv[columns]\n",
    "cu17_final = cu17_merged_conv[columns]\n",
    "# cu0_final['race_code'] = 'W'\n",
    "combined = pd.concat([cu0_final, cu17_final], axis=0)\n",
    "combined['cdr'] = combined.apply(cdr_val, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv(f'fhs_combined_cu0_cu17_{diff_months}months.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to UDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hispanic(row):\n",
    "    if (isinstance(row['race_code'], str)):\n",
    "        if 'E' in row['race_code']:\n",
    "            return 0.0\n",
    "        elif 'H' in row['race_code']:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return np.NaN\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "def race(row):\n",
    "    if not isinstance(row['race_code'], str):\n",
    "        return np.NaN\n",
    "    codes = set([code for code in list(row['race_code']) if code != 'E' and code != 'H'])\n",
    "    if len(codes) > 1 or len(codes) == 0:\n",
    "        return np.NaN\n",
    "    matches = {'W': 1, 'B': 2, 'N': 3, 'P': 4, 'A': 5, 'O': 50, 'X': np.NaN, 'R': np.NaN}\n",
    "    return matches[list(codes)[0]]\n",
    "\n",
    "def convert_variables(df):\n",
    "    df['MRI'] = df['mri_id_date']\n",
    "    # df['HISPANIC'] = df.apply(hispanic, axis=1)\n",
    "    # df['NACCNIHR'] = df.apply(race, axis=1)\n",
    "    df['HISPANIC'] = 0.0\n",
    "    df['RACE'] = 1.0\n",
    "    df['NACCNIHR'] = 1.0\n",
    "    df['SEX'] = df['sex']\n",
    "    # df['NACCNIHR'] = df['race_code'].replace({'W': 1, 'B': 2, 'A': 5, 'P': 4, 'N': 3, 'O': 50, 'R': 99}).astype(float)\n",
    "    \n",
    "    df['NACCAGE'] = df['age_core'].astype(float)\n",
    "    df['WEIGHT'] = df['weight_core'].astype(float)\n",
    "    df['HEIGHT'] = df['height_core'].astype(float)\n",
    "    df['NACCBMI'] = df['bmi_core'].astype(float)\n",
    "    df['TOBAC30'] = df['smoking_core'].astype(float)\n",
    "    df['BPSYS'] = df['sbp_core'].astype(float)\n",
    "    df['BPDIAS'] = df['dbp_core'].astype(float)\n",
    "    df['NACCDBMD'] = df['dmrx_core'].astype(float)\n",
    "    df['NACCLIPL'] = df['liprx_core'].astype(float)\n",
    "    df['NACCMMSE'] = df['cogscr_core'].astype(float)\n",
    "    df['HXSTROKE'] = df['prevalent_stroke_core'].replace({0.0: 0, 1.0: 2}).astype(float)\n",
    "    df['AFIBRILL'] = df['prevalent_af_core'].astype(float)\n",
    "    \n",
    "    df['MARISTAT'] = df['marital_np'].replace({1.0: 5, 2.0: 1, 3.0: 2, 4.0: 3, 5.0: 4, 6.0: 9}).astype(float)\n",
    "    df['HANDED'] = df['handedness_np'].replace({1.0: 2, 2.0: 1, 3.0: 3}).astype(float)\n",
    "    df['BOSTON'] = df['bnt30_np'].astype(float)\n",
    "    \n",
    "    df['CDRGLOB'] = df['cdr'].astype(float)\n",
    "    \n",
    "    return df\n",
    "\n",
    "combined_converted = convert_variables(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    2970\n",
       "Name: NACCNIHR, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_converted['NACCNIHR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['AD', 'LBD', 'VD', 'FTD']\n",
    "for lab in labels + ['NC', 'MCI', 'DE']:\n",
    "    combined_converted[lab] = np.NaN\n",
    "\n",
    "def labels_conversion(row):\n",
    "    # print(type(row['demrv046']), type(row['demrv103']))\n",
    "    # if not isinstance(row['demrv046'], float):\n",
    "    #     return row\n",
    "    if row['demrv046'] == 0 and row['demrv103' ] == 0:\n",
    "        row['NC'] = 1\n",
    "        row['MCI'] = 0\n",
    "        row['DE'] = 0\n",
    "        for lab in labels:\n",
    "            row[lab] = 0\n",
    "    elif row['demrv046'] == 0 and row['demrv103' ] == 9:\n",
    "        row['NC'] = 0\n",
    "        row['MCI'] = 1\n",
    "        row['DE'] = 0\n",
    "        for lab in labels:\n",
    "            row[lab] = 0\n",
    "            \n",
    "    elif row['demrv046'] == 1:\n",
    "        row['NC'] = 0\n",
    "        row['MCI'] = 0\n",
    "        row['DE'] = 1\n",
    "        \n",
    "        if row['demrv103' ]== 1 or row['demrv103' ]== 2:\n",
    "            row['AD'] = 1\n",
    "            for lab in labels:\n",
    "                if lab != 'AD':\n",
    "                    row[lab] = 0\n",
    "        elif row['demrv103' ]== 3:\n",
    "            row['VD'] = 1\n",
    "            for lab in labels:\n",
    "                if lab != 'VD':\n",
    "                    row[lab] = 0\n",
    "        elif row['demrv103' ]== 4:\n",
    "            row['AD'] = 1\n",
    "            row['VD'] = 1\n",
    "            for lab in labels:\n",
    "                if lab != 'AD' and lab != 'VD':\n",
    "                    row[lab] = 0\n",
    "        elif row['demrv103' ]== 5:\n",
    "            row['FTD'] = 1\n",
    "            for lab in labels:\n",
    "                if lab != 'FTD':\n",
    "                    row[lab] = 0\n",
    "        elif row['demrv103' ]== 6:\n",
    "            row['LBD'] = 1\n",
    "            for lab in labels:\n",
    "                if lab != 'LBD':\n",
    "                    row[lab] = 0\n",
    "    \n",
    "    return row\n",
    "\n",
    "combined_converted = combined_converted.apply(labels_conversion, axis=1)\n",
    "combined_converted.dropna(subset=['NC', 'MCI', 'DE'] + labels, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = ['id', 'idtype', 'framid', 'demrv046', 'demrv103', 'normal_date', 'impairment_date', 'mild_date', 'moderate_date', 'severe_date', 'diag_date', 'mri_date', 'mri_dst'] + ['NC', 'MCI', 'DE'] + labels + ['MRI', 'SEX', 'HISPANIC', 'RACE', 'NACCNIHR', 'NACCAGE', 'WEIGHT', 'HEIGHT', 'NACCBMI', 'TOBAC30', 'BPSYS', 'BPDIAS', 'NACCDBMD', 'NACCLIPL', 'NACCMMSE', 'HXSTROKE', 'AFIBRILL', 'MARISTAT', 'HANDED', 'BOSTON', 'CDRGLOB', 'neuropath_avail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_final = combined_converted[final_columns]\n",
    "combined_final.to_csv(f'fhs_converted_{diff_months}months.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adrd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2fee1eeda00f634ef393c368cf80d2602caace706932955f6e4df5f01719481"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
